# -*- coding: utf-8 -*-
"""Student-Performance-Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13xTdvGKNNgHodY7RWNBjg-aeADCKeVQc
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)
# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""# Importing Data"""

# Load the dataset
df = pd.read_csv('Student_performance_data _.csv')
df.head()

from google.colab import drive
drive.mount('/content/drive')

"""**Display Dataset Information**"""

df.info()

"""**Statistical Summary of the Dataset**"""

df.describe()

"""# Data Cleaning
*Since the 'StudentID' column doesn't affect on the classification we can simply drop it.*
*Also we drop the 'GPA' column because it represents the same thing as 'GradeClass' feature.*
"""

df = df.drop(['StudentID','GPA'], axis = 1)
df.head()

"""# Feature Engineering"""

df['ParentalEducation_StudyTime'] = df['ParentalEducation'] * df['StudyTimeWeekly']
df['StudyAbsenceRatio'] = df['StudyTimeWeekly'] / (df['Absences'] + 1)
df.head()

"""# Data Visualization"""

palette = px.colors.qualitative.Set2

correlation_matrix = df.corr()

correlation_with_GradeClass = correlation_matrix['GradeClass'].sort_values(ascending=False)

fig = px.bar(correlation_with_GradeClass,
             title='Correlation of Features with GradeClass',
             labels={'index': 'Features', 'value': 'Correlation Coefficient'},
             color_discrete_sequence=palette)
fig.update_layout(xaxis={'categoryorder':'total descending'})
fig.show()

"""**Histograms of some Numerical Features**"""

numerical_cols = ['Age', 'StudyTimeWeekly', 'Absences']

fig = px.histogram(df, x=numerical_cols[0], nbins=20, title=f'Histogram of {numerical_cols[0]}', color_discrete_sequence=palette)
for col in numerical_cols[1:]:
    fig.add_trace(go.Histogram(x=df[col], nbinsx=20, name=col))
fig.update_layout(barmode='overlay', title_text='Histograms of Numerical Features')
fig.update_traces(opacity=0.75)
fig.show()

"""Violin Plot"""

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame and 'GradeClass' is a categorical column
# and 'StudyTimeWeekly' is a numerical column you want to visualize

plt.figure(figsize=(10, 6))  # Adjust figure size as needed
sns.violinplot(x='GradeClass', y='StudyTimeWeekly', data=df, inner="box", palette="Set3")
plt.title('Distribution of Study Time Weekly by Grade Class')
plt.xlabel('Grade Class')
plt.ylabel('Study Time Weekly')
plt.show()

"""# Advanced Feature Engineering
**Polynomial Feature Engineering**
"""

from sklearn.preprocessing import PolynomialFeatures

numerical_features = df[['Age', 'StudyTimeWeekly', 'Absences', 'ParentalEducation_StudyTime', 'GradeClass', 'StudyAbsenceRatio']]

poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)
poly_features = poly.fit_transform(numerical_features)

poly_features_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(numerical_features.columns))

df = pd.concat([df, poly_features_df], axis=1)

"""# Data Preparation"""

# Remove duplicate columns if any
df = df.loc[:, ~df.columns.duplicated()]

# Separate features and target variable
x = df.drop('GradeClass', axis=1)
y = df['GradeClass']

"""# Model Preparation
**Train-Test Split**
"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

"""**Data Scaling**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

"""# Model Training and Evaluation
**Train Logistic Regression Model**
"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='liblinear')
model.fit(x_train_scaled, y_train)

"""**Model Prediction**"""

y_pred = model.predict(x_test_scaled)

"""**Model Evaluation**"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

confusion_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(confusion_matrix)

classification_report = classification_report(y_test, y_pred)
print("Classification Report:")
print(classification_report)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""# Accuracy is 96%

### Conclusion

In this analysis, the Logistic Regression model was evaluated on the test set with the following results:

1. **Model Performance:**
   - The model achieved an **accuracy of 96%** on the test set, indicating perfect classification performance.
   - The confusion matrix confirms that all instances were correctly classified, with no misclassifications.

2. **Evaluation Metrics:**
   - The classification report shows perfect precision, recall, and F1-scores for all classes.
   - The accuracy score of 1.0 reflects exceptional performance across all categories.

3. **Implications:**
   - The model's perfect accuracy suggests that it performs very well on this dataset. However, such results may also indicate potential overfitting, especially if the dataset is small or not representative of broader scenarios.

4. **Future Considerations:**
   - **Validation:** To ensure robustness, validate the model on different or larger datasets.
   - **Exploration:** Consider exploring additional models or techniques to compare performance.
   - **Cross-Validation:** Regular cross-validation can help confirm the model’s performance and generalizability.

In summary, the Logistic Regression model demonstrates excellent performance on the current dataset, achieving perfect accuracy and classification metrics. Further validation and exploration will help ensure the model’s applicability and performance in diverse scenarios.

---

If you found this notebook useful, please consider **upvoting** it. Your feedback and support are greatly appreciated!
"""